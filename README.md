# streaming_project

Anal√≠tica de streaming (pel√≠culas, ratings, plataformas) con pipeline ETL ‚Üí PostgreSQL (Neon) ‚Üí BI (Tableau/Power BI) y CI/CD (Jenkins/Docker).

## D√≠a 1 ‚Äì Presentaci√≥n y alcance

**Objetivo:** dejar preparado el entorno de trabajo para iniciar el proyecto de datos.

### Alcance
- **Problema:** integrar y analizar datos de pel√≠culas (TMDB/IMDb/Netflix) para calcular KPIs y hacer predicci√≥n ligera.  
- **Arquitectura:** ETL (Python/SQLAlchemy) ‚Üí Neon (PostgreSQL) ‚Üí Vistas SQL para BI ‚Üí Dashboards (Tableau/Power BI).  
- **CI/CD:** Jenkins + Docker.  

### KPIs iniciales
1. Rating medio por g√©nero  
2. Top N pel√≠culas por plataforma  
3. % de estrenos por a√±o  
4. Distribuci√≥n de t√≠tulos por d√©cada  
5. Crecimiento del cat√°logo por plataforma  

**Evidencias:**  
`docs/day1/architecture.png`, `docs/day1/kpis.md`, `docs/day1/scope.md`

---

## Estructura del proyecto

### plaintext 
```
etl/                    # extract, clean, transform, load
sql/                    # DDL/queries/vistas
dashboards/
  ‚îú‚îÄ tableau/
  ‚îî‚îÄ powerbi/
infra/                  # Dockerfile, Jenkinsfile, Ansible
data/
  ‚îú‚îÄ raw/
  ‚îú‚îÄ clean/
  ‚îî‚îÄ processed/
docs/

python -m venv .venv
source .venv/bin/activate   # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt
cp .env.example .env        # Rellena DATABASE_URL con tu cadena de Neon

docs: visi√≥n, KPIs y arquitectura inicial

```

# D√≠a 2 ‚Äì Creaci√≥n y sincronizaci√≥n del repositorio GitHub

## Objetivo
Conectar el entorno local de desarrollo con GitHub para garantizar control de versiones, visibilidad del c√≥digo y trazabilidad de avances durante la FCT.

---

## Tareas realizadas
1. Crear el repositorio remoto `streaming_project` en GitHub.  
2. Clonar el repositorio mediante **GitHub Desktop** o `git clone`.  
3. Mover la estructura local dentro del repositorio clonado.  
4. Realizar el primer *commit* (`init: estructura base`) y subir los cambios.  
5. Verificar la sincronizaci√≥n local ‚Üî remoto.  

---

## Comandos utilizados

```bash
git init
git remote add origin https://github.com/<usuario>/streaming_project.git
git add .
git commit -m "init: estructura base del proyecto"
git push -u origin main



---

## üìÑ Contenido de `docs/day2/fuentes_datos.md`

```markdown
# Fuentes de datos potenciales (avance D√≠a 3)

## Datasets candidatos
- **TMDB API:** pel√≠culas, ratings, popularidad.  
- **IMDb (BigQuery):** dataset p√∫blico con metadatos y ratings.  
- **Netflix Kaggle Dataset:** CSV con cat√°logo y duraci√≥n.  

## Notas
- Verificar licencias y t√©rminos de uso.  
- Documentar rutas de acceso y claves API en `.env.example`.  
- Guardar ejemplos de respuestas (TMDB API) en `/data/raw/`.


git add docs\day2 data\hello.txt
git commit -m "docs(day2): sincronizaci√≥n GitHub completada y evidencias a√±adidas"
git push
